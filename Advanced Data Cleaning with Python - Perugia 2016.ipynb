{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data Cleaning with Python\n",
    "\n",
    "Welcome! In this session we will show you how you can use Python (2.7, should work on 3.5 as well) clean data! You will get information from a series of spreadsheets that have more or less the same structure and create a single clean CSV file. Pretty rad, huh?\n",
    "\n",
    "This tutorial was inspired by a script I created for J++ SÃ£o Paulo to clean some Brazil's government data and an OpenRefine workshop that Sarah Cohen gave during the Computer Assisted Reporting Conference 2016 (CAR Conference 2016) in Denver, USA.\n",
    "\n",
    "I will assume:\n",
    "\n",
    "- You know what Python, ```CSV``` and ```XLS``` files are;\n",
    "- You know what regular expressions are;\n",
    "- You know what modules/libraries are and how to import them;\n",
    "- You have some basic knowledge of how computer algorithms work (assign values to variables, create if/else tests, control flows - while/for - etc);\n",
    "- You are not afraid of learning a bunch of cool tricks :)\n",
    "\n",
    "Even if you don't know all of the above you should be able to follow!\n",
    "\n",
    "## What will we be using?\n",
    "\n",
    "- Python 2.7 (should work on 3.5 as well, though I haven't tested. Let me know how it goes!);\n",
    "- Built-in Regular Expression (```re```) module to find specific text;\n",
    "- Built-in ```CSV``` module to create and manipulate ```CSV``` files;\n",
    "- ```listdir()``` function from built in ```os``` module, to get the list of file names in a folder; \n",
    "- ```xlrd``` library to manipulate ```XLS``` files. You can install it using ```pip install xlrd```.\n",
    "\n",
    "Let's go ahead and do our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re # Regular Expression library\n",
    "import csv # The CSV library\n",
    "from os import listdir # The listdir() function from the OS library\n",
    "from xlrd import open_workbook # The open_workbook class from the xlrd library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. We should now be able to start cleaning, but a bit of context first.\n",
    "\n",
    "## So what are we doing anyway?\n",
    "\n",
    "Great question. I'll show you how to solve an annoying problem that might pop up anytime during your data journalism career: the data you want is apread across multiple files that **share the same structure between themselves**. This could be the case in a number of situations:\n",
    "\n",
    "- A government agency publishes a report every month on their website with updated information;\n",
    "- A company publishes, every quarter, reports about their financial status;\n",
    "- A civil society organisation releases an ```.xls``` report every week about what's going on in the area they care about;\n",
    "- Any situation where there are a number of files that preserve the same structure between themselves and you want to consolidate all the data together in a single ```CSV``` file for further analysis.\n",
    "\n",
    "We will explore a specific case and learn the techniques to work around the issue. Keep in mind the specific case here is not important. You can extrapolate the approach presented here to apply anywhere else where the same conditions apply. Let's get started!\n",
    "\n",
    "## Our data\n",
    "\n",
    "Every month, the XXXX of the state of New York, in the US, releases a report with information about health care companies (develop....)\n",
    "\n",
    "The published data is in the XLS format. While these reports are useful for human inspection, they can't really be processed by a computer as they are. We need to find a way to put all the information in every single file together and clean it. Sarah Cohen shows how to do it in OpenRefine. You will learn how to do it with Python.\n",
    "\n",
    "## Look for patterns\n",
    "\n",
    "Computers are really good at doing the same thing over and over. What we want is to find common patterns and assign our script to look for them and repeat the procedure until it's finished. Also, we have to make sure the files share the same pattern -- they have the same number of columns, the same categories, they have the same keywords or empty spaces in similar place, etc.\n",
    "\n",
    "To make things easier, I excluded from this excersise files before 2013. Why? Because the Yankee government changed the structure of the files slightly, with a different number of columns and the type of data. Including them would give an extra layer of complexity to this tutorial. Since the files after 2013 share the same basic structure, we will figure out how get the information we want from one of them and assign our script to do the same thing for all the other files.\n",
    "\n",
    "## Design a cleaning strategy\n",
    "\n",
    "### Thinking about columns\n",
    "Think about which columns your final dataset will have. What are you looking for? In our case, it makes sense to think about having the following columns:\n",
    "\n",
    "- ```YEAR```\n",
    "- ```MONTH```\n",
    "- ```COUNTY```\n",
    "- ```PLAN NAME```\n",
    "- ```ADC``` (TANF ADC & MA-ADC)\n",
    "- ```SNA``` (SNA HR & MA-HR)\n",
    "- ```SSI``` (SSI & MA-SSI)\n",
    "- ```NYSoH```\n",
    "- ```TOTAL ENROLLED```\n",
    "\n",
    "The other columns are aggregated numbers that we don't really need. We can get the same numbers by adding the values in the columns above.\n",
    "\n",
    "### Are there and repetitions?\n",
    "Yes! Several! In every file:\n",
    "\n",
    "- ...the information we need is always in the first sheet of the ```XLS``` file\n",
    "- ...dates (month & year) are always in the same cell (```A4```)\n",
    "- ...names of counties and plans are always in the same columns (```A``` & ```B```)\n",
    "- ...the list of plan names always start with the string ```TOTALS:```\n",
    "- ...the county name is always immediately one cell to the left of ```TOTALS:```\n",
    "- ...the list of plan names always end in an empty space (after that we have data for New York city, which we won't capture)\n",
    "\n",
    "### But there is a catch...\n",
    "Notice that in some files the name of the columns are different. There are two cases:\n",
    "\n",
    "- Files with the ```NYSoH``` column\n",
    "- Files without the ```NYSoH``` column\n",
    "\n",
    "No problem. We will take care of each one of those cases populating our ```CSV``` file with the correct data.\n",
    "\n",
    "### Final thoughts about strategy\n",
    "Before starting your cleaning procedure take your time evaluating the files. Write down patterns that are more evident. Watch out for differencies between the files. They might be similar, but have slight differences, such as different column names or aggregated data.\n",
    "\n",
    "\n",
    "# ENOUGH! Show me the code!\n",
    "Alright. Let's get to it.\n",
    "\n",
    "### Getting the date\n",
    "When you open the ```XLS``` files, one of the first things you'll notice is that cell **```A4```** holds the information about the month and year of the current file. That is always the case. We will store this information in two separate columns in our final ```CSV``` files: ```MONTH``` and ```YEAR```. To do that, let's create a helper function that will give us a dictionary with key/value pairs for the ```MONTH``` and for the ```YEAR```. We will use this dictionary later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gets the date from the specific cell in the documents\n",
    "# and use regular expression to separate month from year.\n",
    "# returns a dictionary with YEAR and MONTH\n",
    "def getDate(worksheet):\n",
    "    '''\n",
    "    worksheet: an xlrd book object\n",
    "    :return: dictionary\n",
    "    '''\n",
    "    date = worksheet.cell_value(3, 0)\n",
    "    match = re.match(r'NYS[ ,]+(\\w+)[ ,](\\d+)', date).groups()\n",
    "    date = {'YEAR': match[1],\n",
    "            'MONTH': match[0]\n",
    "            }\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's see how this works.\n",
    "\n",
    "This function needs an ```xlrd``` book object (essentially, the sheet where will extract the information from) that we will create later. It uses the ```cell_value``` method from xlrd to get the contents of a specific cell. The first parameter (3) is the row and the second is the column. Since we want the contents of cell ```A4``` we use the pair 3 (the count starts at zero!) and 0. We store the contents of cell ```A4``` in the variable \"date\".\n",
    "\n",
    "After that we do a regex (Regular Expression) search in our ```date``` variable to extract the month and the year. The yankee government sometimes uses a comma to separate ```NYS``` from the month, sometimes it doesn't, which is frustrating. That also happens between month and year. But no matter! Regex to the rescue.\n",
    "\n",
    "```NYS[ ,]+``` = Match a string that starts with NYS and is followed by either an empty space or a comma and any number of characters after that.\n",
    "\n",
    "```(\\w+)[ ,] =``` Will do our first capture (that's why the parethesis are there): any word after the above followed by an empty space or a comma.\n",
    "\n",
    "```(\\d+)``` = Will do our second capture, any number of digits after the above.\n",
    "\n",
    "With our two values captured, we create our dictionary and return it.\n",
    "\n",
    "### Prep code & storing filenames\n",
    "We will create our ```CSV``` file row by row. So let's create an empty dictionary to store the information about the current row we will be scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also assign the path to the folder where the ```XLS``` files are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basedir = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's use the ```listdir()``` function to get the list of filenames in that folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = listdir(basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go over each and every ```XLS``` file. We need to tell the script which file it will be working on at any given time. Let's make sure our list has only files with the ```XLS``` extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sheets = [filename for filename in files if filename.endswith(\"xls\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! Wait a minute. I just did what is called a list comprehension: get the filenames in the files list but only those which end with ```'xls'```. Pretty cool, right?\n",
    "\n",
    "### Thinking ahead\n",
    "The first line of a ```CSV``` file is usually the name of the columns, you know, the header. Since we will be writing row by row in our ```CSV``` file using a series of repetitions, we need a device to know if we have written the header or not. Let's create a flag that will help us with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_is_written = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set ```header_is_written``` to True after we write the header.\n",
    "\n",
    "## Iterating over the files\n",
    "Ok. Now we're going to scrape the information from all the files in the sheets list we just created. To do that we will start a simple for loop.\n",
    "\n",
    "We will also open the worksheet using ```open_workbook``` from ```xlrd```. Since the information we need is in the first sheet of the file, let's use the ```sheet_by_index()``` method to open that sheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in sheets:\n",
    "    worksheet = open_workbook(basedir + filename).sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the date from this file using the helper function we created in the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    date = getDate(worksheet)\n",
    "    row['YEAR'] = date['YEAR']\n",
    "    row['MONTH'] = date['MONTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we're still inside the loop, so the code needs to be idented. This will be the case moving forward.\n",
    "\n",
    "## Our reference column\n",
    "\n",
    "**Column B** is the most important. It has the name of the plans and all the names of the counties are right next to it. Let's get the values in that column and store them in a list. After that we will iterate over them to get what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    col1_values = worksheet.col_values(1) # column A == 0, column B == 1..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're iterating over ```range``` instead of the values because we need to keep track of the coordinate of the cells. With the coordinates we can get the actual content, so we should be fine.\n",
    "\n",
    "## Getting the data\n",
    "We're all set to get the data we need. Remember we need to get the names of the counties, the name of the plans and the values associated with them. Our reference is the value ```TOTALS:``` in **Column B**. If we find it we will be one cell away from the county name. Let's iterate over the values of **Column B**. If we find ```TOTALS:``` let's save the value immediately to the left in our row dictionary, assigning it to the key ```COUNTY```. We will be using the ```cell_value``` method from ```xlrd```. I'm also using the strip function. It will trim trailing and leading spaces from the cell value, just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    for i in range(len(col1_values)):\n",
    "        if worksheet.cell_value(i, 1) == u'TOTALS:':\n",
    "            row['COUNTY'] = worksheet.cell_value(i, 0).strip()\n",
    "            county = True\n",
    "            counter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get the plan names that are associated with that county. Our robot is still looking for the ```TOTALS:``` value and when it finds it, we will have reached the next county. So let's create a flag called county. ```True``` if the robot doesn't find the next ```TOTALS:```, ```False``` if it hits the next county. Also, since the plan names are the plan names right after ```TOTALS:```, we create a counter that will basically increment the row number by one to get the values down the list until we find another ```TOTALS:```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "            while county is True:\n",
    "                row['PLAN NAME'] = worksheet.cell_value(i + counter, 1).strip()\n",
    "                values = worksheet.row_slice(i + counter, start_colx=2, end_colx=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, while the county flag is ```True```, we will store the ```PLAN NAME``` in the dictionary adding the counter to the position of the row. We're also using the nifty ```row_slice``` method from ```xlrd``` to generate a list of all the associated values for that ```PLAN NAME```, from **Columns C** (2) to **G** (6 - the parameter ```end_colx``` gets up to the number before the one you set).\n",
    "\n",
    "Since we have a list of values in the same order of the columns, we will assign each one of them to the appropriate key in the ```row``` dictionary. The list won't have the actual values, but ```xlrd``` objects with the values. To get the values we need to use the method ```.value```. We're also converting them to integers with the ```int()```  function.\n",
    "\n",
    "# BUT WAIT!\n",
    "\n",
    "Remmeber that some files have the column ```NYSoH``` and others don't. Depending on the case, the values on the list will change places. A simple ```if/else``` statement will take care of that. The ```SSI``` column becomes the 4th number in the list whenever ```NYSoH``` is not present. When ```NYSoH``` is not present, let's give it an empty value.\n",
    "\n",
    "We have to give ```NYSoH``` an empty value because we will be writing rows to the ```CSV``` file. All the rows must have the same amount of values, otherwise things will break.\n",
    "\n",
    "We're also incrementing ```counter``` by 1 so that whenever it goes back to the beginning of the loop, it will look for the row after the one we just stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                if worksheet.cell_value(4,5) == u'NYSoH':\n",
    "                    row['ADC'] = int(values[0].value)\n",
    "                    row['SNA'] = int(values[1].value)\n",
    "                    row['SSI'] = int(values[2].value)\n",
    "                    row['NYSoH'] = int(values[3].value)\n",
    "                    row['TOTAL'] = int(values[4].value)\n",
    "                else:\n",
    "                    row['ADC'] = int(values[0].value)\n",
    "                    row['SNA'] = int(values[1].value)\n",
    "                    row['SSI'] = int(values[3].value)\n",
    "                    row['NYSoH'] = \"\"\n",
    "                    row['TOTAL'] = int(values[4].value)\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is good. We have the info we need to write the row in the ```CSV``` file. Before we do that, let's set the county flag to False if it finds ```TOTALS:``` once it increments the counter. Also, if the ```PLAN NAME``` in that row was assigned an empty space, it means we reached the end of the counties column. The empty space is what separates the data from the counties from the data for New York city. If that's the case, we will break to get outside of this loop and go to the next file without writing the row with the empty space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "                if worksheet.cell_value(i + counter, 1) == u'TOTALS:':\n",
    "                    county = False\n",
    "                # If we reach a point in this column that the value is blank, it means our search in this file is over!\n",
    "                elif row['PLAN NAME'] == '':\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. Time to write the row dictionary to the ```CSV file```. Easy. We will use the ```CSV``` module we imported earlier. Remember the flag we created for the header? The handy thing about having stored all the row information in a dictionary is that we can use the ```writeheader()``` function to get the name of the keys and write the header. Once we do that, we update the ```header_is_written``` flag to ```True``` and never use it again, since we need to do this only once, at the very first iteration :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                # Saving the row in the CSV file...\n",
    "                with open('table.csv', 'ab') as f:\n",
    "                    w = csv.DictWriter(f, row.keys())\n",
    "                    if header_is_written is False:\n",
    "                        w.writeheader()\n",
    "                        header_is_written = True\n",
    "                    w.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it?\n",
    "\n",
    "Yeah. That's it.\n",
    "\n",
    "There's no formula that will fit all files. Every situation will bring new challenges and you will have to figure out what the patterns are and the best way to approach them. There are many ways to clean the same file. We could have used a column other than B as our reference, for example. Use the approach that makes more sense to you.\n",
    "\n",
    "Let's take a look at the whole code, shall we? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from xlrd import open_workbook\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "# Gets the date from the specific cell in the documents\n",
    "# and use regular expression to separate month from year.\n",
    "# returns a dictionary with YEAR and MONTH\n",
    "def getDate(worksheet):\n",
    "    '''\n",
    "    :param worksheet:\n",
    "    :return: dictionary\n",
    "    '''\n",
    "    date = worksheet.cell_value(3, 0)\n",
    "    match = re.match(r'NYS[ ,]+(\\w+)[ ,](\\d+)', date).groups()\n",
    "    date = {'YEAR': match[1],\n",
    "            'MONTH': match[0]\n",
    "            }\n",
    "    return date\n",
    "\n",
    "# Empty dictionary where we will store each row, before parsing it to the CSV\n",
    "row = {}\n",
    "\n",
    "# This is where the xls files are\n",
    "basedir = 'data/'\n",
    "\n",
    "# This is an os function that returns a list of filenames in a folder\n",
    "files = listdir(basedir)\n",
    "\n",
    "# Empty list to store only XLS files found in the folder\n",
    "sheets = [filename for filename in files if filename.endswith(\"xls\")]\n",
    "\n",
    "header_is_written = False\n",
    "# Iterating over the files in folder\n",
    "for filename in sheets:\n",
    "    # Opens the xls file\n",
    "    worksheet = open_workbook(basedir+filename).sheet_by_index(0)\n",
    "    # Get the date from it\n",
    "    date = getDate(worksheet)\n",
    "    row['YEAR'] = date['YEAR']\n",
    "    row['MONTH'] = date['MONTH']\n",
    "    # We're going to iterate over all the values in column[1]\n",
    "    col1_values = worksheet.col_values(1)\n",
    "    for i in range(len(col1_values)):\n",
    "        if worksheet.cell_value(i, 1) == u'TOTALS:':\n",
    "            row['COUNTY'] = worksheet.cell_value(i, 0).strip()\n",
    "            county = True\n",
    "            counter = 1\n",
    "            # While we're in that county, let's save all the data it has for different plan names\n",
    "            while county is True:\n",
    "                row['PLAN NAME'] = worksheet.cell_value(i + counter, 1).strip()\n",
    "                values = worksheet.row_slice(i + counter, start_colx=2, end_colx=7)\n",
    "                if worksheet.cell_value(4,5) == u'NYSoH':\n",
    "                    row['ADC'] = int(values[0].value)\n",
    "                    row['SNA'] = int(values[1].value)\n",
    "                    row['SSI'] = int(values[2].value)\n",
    "                    row['NYSoH'] = int(values[3].value)\n",
    "                    row['TOTAL'] = int(values[4].value)\n",
    "                else:\n",
    "                    row['ADC'] = int(values[0].value)\n",
    "                    row['SNA'] = int(values[1].value)\n",
    "                    row['SSI'] = int(values[3].value)\n",
    "                    row['NYSoH'] = \"\"\n",
    "                    row['TOTAL'] = int(values[4].value)\n",
    "                counter += 1\n",
    "                # If the robot finds another cell with the value \"TOTALS:\", it means we reached another county\n",
    "                # Time to break and start again\n",
    "                if worksheet.cell_value(i + counter, 1) == u'TOTALS:':\n",
    "                    county = False\n",
    "                # If we reach a point in this column that the value is blank, it means our search is over!\n",
    "                elif row['PLAN NAME'] == '':\n",
    "                    break\n",
    "                # Saving the row in the CSV file...\n",
    "                with open('table.csv', 'ab') as f:\n",
    "                    w = csv.DictWriter(f, row.keys())\n",
    "                    if header_is_written is False:\n",
    "                        w.writeheader()\n",
    "                        header_is_written = True\n",
    "                    w.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
